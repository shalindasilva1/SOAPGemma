{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-18T15:15:42.302674Z",
     "start_time": "2025-05-18T15:15:42.295039Z"
    }
   },
   "source": [
    "import torch\n",
    "import bitsandbytes as bnb\n",
    "from pathlib import Path\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from datasets import Dataset\n",
    "\n",
    "DATA_PATH = Path(\"../data\")\n",
    "OMI_PATH_processed = DATA_PATH / \"processed\" / \"omi-health\"\n",
    "OMI_PATH_raw = DATA_PATH / \"raw\" / \"omi-health\"\n",
    "MODEL_PATH =  Path(\"../models\")\n",
    "\n",
    "print(f\"PyTorch CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device count: {torch.cuda.device_count()}\")\n",
    "    print(f\"Current CUDA device name: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "print(f\"Bitsandbytes version: {bnb.__version__}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch CUDA available: True\n",
      "CUDA device count: 1\n",
      "Current CUDA device name: NVIDIA RTX A4000\n",
      "Bitsandbytes version: 0.45.5\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T14:29:08.016015Z",
     "start_time": "2025-05-18T14:27:31.842103Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_id = \"google/txgemma-2b-predict\"\n",
    "\n",
    "# Use 4-bit quantization to reduce memory usage\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    quantization_config=quantization_config,\n",
    "    device_map={\"\":0},\n",
    "    torch_dtype=\"auto\",\n",
    "    attn_implementation=\"eager\",\n",
    ")"
   ],
   "id": "80e9405da260a5a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]C:\\Users\\khal6952\\.conda\\envs\\medical-soap-note-generator\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\khal6952\\.cache\\huggingface\\hub\\models--google--txgemma-2b-predict. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Fetching 3 files: 100%|██████████| 3/3 [01:28<00:00, 29.37s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:05<00:00,  1.77s/it]\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T14:31:22.886941Z",
     "start_time": "2025-05-18T14:31:21.539473Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "train_df = pd.read_csv(OMI_PATH_processed / \"train_v1.csv\")\n",
    "train_df.head()"
   ],
   "id": "b153b9a487c93b0e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                            dialogue  \\\n",
       "0  Doctor: Hello, how can I help you today?\\nPati...   \n",
       "1  Doctor: Hello, what brings you in today?\\nPati...   \n",
       "2  Doctor: Hello, how can I help you today?\\nPati...   \n",
       "3  Doctor: Hello, Patient D. How are you feeling ...   \n",
       "4  Doctor: Hello, I see that you have a history o...   \n",
       "\n",
       "                                                soap  \\\n",
       "0  S: The patient's mother reports that her 13-ye...   \n",
       "1  S: The patient, a 21-month-old male, presented...   \n",
       "2  S: Patient reports experiencing fatigue, night...   \n",
       "3  S: Patient D, a 60-year-old African American m...   \n",
       "4  S: The patient, a married woman with a 7-year ...   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  Create a Medical SOAP note summary from the di...   \n",
       "1  Create a Medical SOAP note summary from the di...   \n",
       "2  Create a Medical SOAP note summary from the di...   \n",
       "3    Create a medical SOAP summary of this dialogue.   \n",
       "4  Create a Medical SOAP note summary from the di...   \n",
       "\n",
       "                                            messages  \\\n",
       "0  [{'role': 'system', 'content': 'You are an exp...   \n",
       "1  [{'role': 'system', 'content': 'You are an exp...   \n",
       "2  [{'role': 'system', 'content': 'You are an exp...   \n",
       "3  [{'role': 'system', 'content': 'You are an exp...   \n",
       "4  [{'role': 'system', 'content': 'You are an exp...   \n",
       "\n",
       "                                   messages_nosystem  \\\n",
       "0  [{'role': 'user', 'content': \"You are an exper...   \n",
       "1  [{'role': 'user', 'content': \"You are an exper...   \n",
       "2  [{'role': 'user', 'content': \"You are an exper...   \n",
       "3  [{'role': 'user', 'content': \"You are an exper...   \n",
       "4  [{'role': 'user', 'content': \"You are an exper...   \n",
       "\n",
       "                                          event_tags  \n",
       "0                              ['(After the tests)']  \n",
       "1  ['[After the tests]', '[After 3 weeks of thera...  \n",
       "2                                                 []  \n",
       "3                                                 []  \n",
       "4                                                 []  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dialogue</th>\n",
       "      <th>soap</th>\n",
       "      <th>prompt</th>\n",
       "      <th>messages</th>\n",
       "      <th>messages_nosystem</th>\n",
       "      <th>event_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Doctor: Hello, how can I help you today?\\nPati...</td>\n",
       "      <td>S: The patient's mother reports that her 13-ye...</td>\n",
       "      <td>Create a Medical SOAP note summary from the di...</td>\n",
       "      <td>[{'role': 'system', 'content': 'You are an exp...</td>\n",
       "      <td>[{'role': 'user', 'content': \"You are an exper...</td>\n",
       "      <td>['(After the tests)']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Doctor: Hello, what brings you in today?\\nPati...</td>\n",
       "      <td>S: The patient, a 21-month-old male, presented...</td>\n",
       "      <td>Create a Medical SOAP note summary from the di...</td>\n",
       "      <td>[{'role': 'system', 'content': 'You are an exp...</td>\n",
       "      <td>[{'role': 'user', 'content': \"You are an exper...</td>\n",
       "      <td>['[After the tests]', '[After 3 weeks of thera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Doctor: Hello, how can I help you today?\\nPati...</td>\n",
       "      <td>S: Patient reports experiencing fatigue, night...</td>\n",
       "      <td>Create a Medical SOAP note summary from the di...</td>\n",
       "      <td>[{'role': 'system', 'content': 'You are an exp...</td>\n",
       "      <td>[{'role': 'user', 'content': \"You are an exper...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Doctor: Hello, Patient D. How are you feeling ...</td>\n",
       "      <td>S: Patient D, a 60-year-old African American m...</td>\n",
       "      <td>Create a medical SOAP summary of this dialogue.</td>\n",
       "      <td>[{'role': 'system', 'content': 'You are an exp...</td>\n",
       "      <td>[{'role': 'user', 'content': \"You are an exper...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Doctor: Hello, I see that you have a history o...</td>\n",
       "      <td>S: The patient, a married woman with a 7-year ...</td>\n",
       "      <td>Create a Medical SOAP note summary from the di...</td>\n",
       "      <td>[{'role': 'system', 'content': 'You are an exp...</td>\n",
       "      <td>[{'role': 'user', 'content': \"You are an exper...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T14:49:16.673743Z",
     "start_time": "2025-05-18T14:49:16.666262Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def format_dialogue_for_soap_synthesis_v2(data):\n",
    "    dialogue = data[\"dialogue\"]\n",
    "    soap = data[\"completion\"]\n",
    "    return f\"dialogue: {dialogue}<soap_start> {soap} <eos>\""
   ],
   "id": "4c49074f58bd3466",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T14:51:30.981626Z",
     "start_time": "2025-05-18T14:51:30.216337Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = Dataset.from_pandas(train_df)\n",
    "dataset = dataset.rename_column('soap', 'completion')\n",
    "\n",
    "dataset"
   ],
   "id": "e5b5b9a167e66650",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['dialogue', 'completion', 'prompt', 'messages', 'messages_nosystem', 'event_tags'],\n",
       "    num_rows: 9250\n",
       "})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T14:51:33.465317Z",
     "start_time": "2025-05-18T14:51:33.453160Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from peft import LoraConfig\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"o_proj\",\n",
    "        \"k_proj\",\n",
    "        \"v_proj\",\n",
    "        \"gate_proj\",\n",
    "        \"up_proj\",\n",
    "        \"down_proj\",\n",
    "    ],\n",
    ")"
   ],
   "id": "5832f3407ed2a951",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T14:51:36.779169Z",
     "start_time": "2025-05-18T14:51:36.527783Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from peft import prepare_model_for_kbit_training, get_peft_model\n",
    "\n",
    "# Preprocess quantized model for training\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "# Create PeftModel from quantized model and configuration\n",
    "model = get_peft_model(model, lora_config)"
   ],
   "id": "732a05aa0b42cf5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\khal6952\\.conda\\envs\\medical-soap-note-generator\\Lib\\site-packages\\peft\\mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
      "  warnings.warn(\n",
      "C:\\Users\\khal6952\\.conda\\envs\\medical-soap-note-generator\\Lib\\site-packages\\peft\\tuners\\tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T14:51:54.197857Z",
     "start_time": "2025-05-18T14:51:38.043901Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import transformers\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset,\n",
    "    args=SFTConfig(\n",
    "        per_device_train_batch_size=1,\n",
    "        gradient_accumulation_steps=4,\n",
    "        warmup_steps=20,\n",
    "        max_steps=500,\n",
    "        learning_rate=2e-4,\n",
    "        fp16=True,\n",
    "        logging_steps=5,\n",
    "        max_seq_length=512,\n",
    "        output_dir=\"/content/outputs\",\n",
    "        optim=\"paged_adamw_8bit\",\n",
    "        report_to=\"none\",\n",
    "    ),\n",
    "    peft_config=lora_config,\n",
    "    formatting_func=format_dialogue_for_soap_synthesis_v2,\n",
    ")"
   ],
   "id": "77f8053376bf1891",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying formatting function to train dataset: 100%|██████████| 9250/9250 [00:00<00:00, 12986.17 examples/s]\n",
      "Converting train dataset to ChatML: 100%|██████████| 9250/9250 [00:00<00:00, 11153.36 examples/s]\n",
      "Adding EOS to train dataset: 100%|██████████| 9250/9250 [00:00<00:00, 12064.56 examples/s]\n",
      "Tokenizing train dataset: 100%|██████████| 9250/9250 [00:12<00:00, 736.50 examples/s]\n",
      "Truncating train dataset: 100%|██████████| 9250/9250 [00:00<00:00, 117028.57 examples/s]\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T15:13:44.918912Z",
     "start_time": "2025-05-18T14:51:55.898811Z"
    }
   },
   "cell_type": "code",
   "source": "trainer.train()",
   "id": "ebb836595cd5e59b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\khal6952\\.conda\\envs\\medical-soap-note-generator\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 21:45, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>16.453000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>15.947400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>13.262100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>7.866200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>5.936500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>4.485400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>3.885000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>3.354300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>3.045200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>3.047300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>2.755500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2.611700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>2.578800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>2.632100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>2.620100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>2.433500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>2.562800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>2.581300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>2.334100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.357000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>2.442000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>2.471300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115</td>\n",
       "      <td>2.349100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>2.307100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>2.311800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>2.344500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135</td>\n",
       "      <td>2.312000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>2.238400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145</td>\n",
       "      <td>2.400700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>2.335400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155</td>\n",
       "      <td>2.226200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>2.294200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>165</td>\n",
       "      <td>2.161100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>2.224900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>2.232500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>2.194400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>185</td>\n",
       "      <td>2.153600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>2.263800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>195</td>\n",
       "      <td>2.272800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.289000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>205</td>\n",
       "      <td>2.256700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>2.165000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>215</td>\n",
       "      <td>2.188400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>2.143400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>2.133300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>2.143300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>235</td>\n",
       "      <td>2.195400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>2.229900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>245</td>\n",
       "      <td>2.181900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>2.216100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>255</td>\n",
       "      <td>2.175300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>2.259300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>265</td>\n",
       "      <td>2.182300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>2.146700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>2.098000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>2.154100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>285</td>\n",
       "      <td>2.155400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>2.132700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>295</td>\n",
       "      <td>2.148500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>2.035900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>305</td>\n",
       "      <td>2.025900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>2.161300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>315</td>\n",
       "      <td>2.184700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>2.080800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>2.067900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>2.216700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>335</td>\n",
       "      <td>2.119300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>2.114100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>345</td>\n",
       "      <td>1.998600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1.998800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>355</td>\n",
       "      <td>2.140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>2.156400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>365</td>\n",
       "      <td>2.193900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>2.053100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>2.095600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>2.216600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>385</td>\n",
       "      <td>2.116400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>2.114900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>395</td>\n",
       "      <td>2.078500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.196400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>405</td>\n",
       "      <td>2.055900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>2.061600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>415</td>\n",
       "      <td>2.074200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>2.200800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>2.093900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>2.184600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>435</td>\n",
       "      <td>2.010600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>2.031600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>445</td>\n",
       "      <td>2.085500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>2.055700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>455</td>\n",
       "      <td>2.142000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>1.995700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>465</td>\n",
       "      <td>2.026800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>1.987200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>2.048200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>2.120800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>485</td>\n",
       "      <td>2.068200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>2.029200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>495</td>\n",
       "      <td>2.061600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.048800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=500, training_loss=2.756281015396118, metrics={'train_runtime': 1308.8063, 'train_samples_per_second': 1.528, 'train_steps_per_second': 0.382, 'total_flos': 1.1355701297624064e+16, 'train_loss': 2.756281015396118})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T14:45:37.583791Z",
     "start_time": "2025-05-18T14:45:37.567650Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_soap_note(dialogue, model, tokenizer, device=\"cuda:0\"):\n",
    "    \"\"\"Generates a SOAP note from a given dialogue.\"\"\"\n",
    "\n",
    "    # Format the input (you might need to adapt this based on your training format)\n",
    "    input_text = f\"{dialogue} []<eos>\"  # Assuming empty event tags for simplicity\n",
    "\n",
    "    # Tokenize the input\n",
    "    inputs = tokenizer.encode_plus(\n",
    "        input_text, return_tensors=\"pt\"\n",
    "    ).to(device)\n",
    "\n",
    "    # Generate the SOAP note\n",
    "    outputs = model.generate(\n",
    "        inputs.input_ids,\n",
    "        max_length=2048,  # Adjust as needed\n",
    "        num_beams=4,\n",
    "        temperature=0.7,\n",
    "        early_stopping=True,\n",
    "    )\n",
    "\n",
    "    # Decode the output\n",
    "    soap_note = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return soap_note"
   ],
   "id": "c4b075eb2a668dc2",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T15:16:35.763848Z",
     "start_time": "2025-05-18T15:16:35.405451Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save the fine-tuned model\n",
    "model.save_pretrained(MODEL_PATH)\n",
    "\n",
    "# Save the tokenizer\n",
    "tokenizer.save_pretrained(MODEL_PATH)\n",
    "\n",
    "print(f\"Model and tokenizer saved to {MODEL_PATH}\")"
   ],
   "id": "768560d391533498",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer saved to ..\\models\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T15:16:54.627794Z",
     "start_time": "2025-05-18T15:16:51.554148Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sample_dialogue = train_df.iloc[0,0]\n",
    "generated_note = generate_soap_note(sample_dialogue, model, tokenizer)\n",
    "print(\"Generated SOAP Note:\")\n",
    "print(generated_note)"
   ],
   "id": "88ca60c10b2641b6",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\khal6952\\.conda\\envs\\medical-soap-note-generator\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\khal6952\\.conda\\envs\\medical-soap-note-generator\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\khal6952\\.conda\\envs\\medical-soap-note-generator\\Lib\\site-packages\\torch\\utils\\checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated SOAP Note:\n",
      "Doctor: Hello, how can I help you today?\n",
      "Patient: My son has been having some issues with speech and development. He's 13 years old now.\n",
      "Doctor: I see. Can you tell me more about his symptoms? Does he have any issues with muscle tone or hypotonia?\n",
      "Patient: No, he doesn't have hypotonia. But he has mild to moderate speech and developmental delay, and he's been diagnosed with attention deficit disorder.\n",
      "Doctor: Thank you for sharing that information. We'll run some tests, including an MRI, to get a better understanding of your son's condition. \n",
      "(After the tests)\n",
      "Doctor: The MRI results are in, and I'm glad to say that there are no structural brain anomalies. However, I did notice some physical characteristics. Does your son have any facial features like retrognathia, mild hypertelorism, or a slightly elongated philtrum and thin upper lip?\n",
      "Patient: Yes, he has all of those features. His hands are also broad and short. And his feet have mild syndactyly of the second and third toe, with a sandal gap in both feet.\n",
      "Doctor: Thank you for confirming that. We also conducted Whole Exome Sequencing (WES) analyses, and we found a de novo frameshift variant in his genetic makeup. Specifically, it's Chr1(GRCh37):g.244217335del, NM_205768.2(ZBTB18):c.259del(p.(Leu87Cysfs*21)). This leads to a premature termination codon located more than 400 codons upstream of the canonical termination codon.\n",
      "Patient: What does that mean for my son?\n",
      "Doctor: This genetic variant may be contributing to your son's speech, developmental delay, and attention deficit disorder. It's important that we continue monitoring his progress and provide appropriate support for his development.\n",
      "Patient: What should we do for follow-up?\n",
      "Doctor: Regular visits with a speech and language therapist, an occupational therapist, and a psychologist can help address your son's developmental and attention deficit disorder needs. I will also recommend regular check-ups with me to monitor his growth and overall health.\n",
      "Patient: Thank you, doctor. We will follow your recommendations and keep an eye on his progress. []\n"
     ]
    }
   ],
   "execution_count": 30
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
